{"cells":[{"cell_type":"markdown","id":"fb7a2f86","metadata":{"id":"fb7a2f86"},"source":["# Speech Transcription on IPUs using Whisper - Inference\n","\n","This notebook demonstrates speech transcription on the IPU using the [Whisper implementation in the Hugging Face Transformers library](https://huggingface.co/spaces/openai/whisper) alongside [Optimum Graphcore](https://github.com/huggingface/optimum-graphcore).\n","\n","Whisper is a versatile speech recognition model that can transcribe speech as well as perform multi-lingual translation and recognition tasks.\n","It was trained on diverse datasets to give human-level speech recognition performance without the need for fine-tuning.\n","\n","[ğŸ¤— Optimum Graphcore](https://github.com/huggingface/optimum-graphcore) is the interface between the [ğŸ¤— Transformers library](https://huggingface.co/docs/transformers/index) and [Graphcore IPUs](https://www.graphcore.ai/products/ipu).\n","It provides a set of tools enabling model parallelization and loading on IPUs, training and fine-tuning on all the tasks already supported by ğŸ¤— Transformers while being compatible with the ğŸ¤— Hub and every model available on it out of the box.\n","\n","> **Hardware requirements:** The Whisper models `whisper-tiny`, `whisper-base` and `whisper-small` can run two replicas on the smallest IPU-POD4 machine. The most capable model, `whisper-large`, will need to use either an IPU-POD16 or a Bow Pod16 machine. Please contact Graphcore if you'd like assistance running model sizes that don't work in this simple example notebook.\n","\n","[![Join our Slack Community](https://img.shields.io/badge/Slack-Join%20Graphcore's%20Community-blue?style=flat-square&logo=slack)](https://www.graphcore.ai/join-community)"]},{"cell_type":"markdown","id":"44e8c3fc","metadata":{"id":"44e8c3fc"},"source":["## Environment setup\n","\n","The best way to run this demo is on Paperspace Gradient's cloud IPUs because everything is already set up for you.\n","\n","To run the demo using other IPU hardware, you need to have the Poplar SDK enabled. Refer to the [Getting Started guide](https://docs.graphcore.ai/en/latest/getting-started.html#getting-started) for your system for details on how to enable the Poplar SDK. Also refer to the [Jupyter Quick Start guide](https://docs.graphcore.ai/projects/jupyter-notebook-quick-start/en/latest/index.html) for how to set up Jupyter to be able to run this notebook on a remote IPU machine."]},{"cell_type":"markdown","id":"4be57731","metadata":{"id":"4be57731"},"source":["## Dependencies"]},{"cell_type":"markdown","id":"e6c99e95","metadata":{"id":"e6c99e95"},"source":["In order to improve usability and support for future users, Graphcore would like to collect information about the\n","applications and code being run in this notebook. The following information will be anonymised before being sent to Graphcore:\n","\n","- User progression through the notebook\n","- Notebook details: number of cells, code being run and the output of the cells\n","- Environment details\n","\n","You can disable logging at any time by running `%unload_ext graphcore_cloud_tools.notebook_logging.gc_logger` from any cell."]},{"cell_type":"markdown","id":"070d9b99","metadata":{"id":"070d9b99"},"source":["Install the dependencies the notebook needs."]},{"cell_type":"code","execution_count":1,"id":"fde99b10-e2d2-4787-877f-fb120e327ccb","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"fde99b10-e2d2-4787-877f-fb120e327ccb","executionInfo":{"status":"ok","timestamp":1700898264609,"user_tz":-540,"elapsed":79067,"user":{"displayName":"ë°•ì¤€ì¼","userId":"10460237312093264831"}},"outputId":"4bb0c970-6977-4ab0-efd5-d1aeb9ba5619"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/huggingface/optimum-graphcore.git@1f13c9279921bd064a0a857b044d9c18f7fbca13\n","  Cloning https://github.com/huggingface/optimum-graphcore.git (to revision 1f13c9279921bd064a0a857b044d9c18f7fbca13) to /tmp/pip-req-build-g8g6_bzv\n","  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/optimum-graphcore.git /tmp/pip-req-build-g8g6_bzv\n","  Running command git rev-parse -q --verify 'sha^1f13c9279921bd064a0a857b044d9c18f7fbca13'\n","  Running command git fetch -q https://github.com/huggingface/optimum-graphcore.git 1f13c9279921bd064a0a857b044d9c18f7fbca13\n","  Running command git checkout -q 1f13c9279921bd064a0a857b044d9c18f7fbca13\n","  Resolved https://github.com/huggingface/optimum-graphcore.git to commit 1f13c9279921bd064a0a857b044d9c18f7fbca13\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting tokenizers<0.13\n","  Downloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting transformers==4.25.1\n","  Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (0.19.4)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (2.31.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.25.1) (4.66.1)\n","Collecting optimum==1.6.1 (from optimum-graphcore==0.6.0.dev0)\n","  Downloading optimum-1.6.1-py3-none-any.whl (222 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m222.6/222.6 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting diffusers[torch]==0.12.1 (from optimum-graphcore==0.6.0.dev0)\n","  Downloading diffusers-0.12.1-py3-none-any.whl (604 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m604.0/604.0 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting datasets (from optimum-graphcore==0.6.0.dev0)\n","  Downloading datasets-2.15.0-py3-none-any.whl (521 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m521.2/521.2 kB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting typeguard (from optimum-graphcore==0.6.0.dev0)\n","  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n","Collecting sentencepiece (from optimum-graphcore==0.6.0.dev0)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from optimum-graphcore==0.6.0.dev0) (1.11.3)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from optimum-graphcore==0.6.0.dev0) (9.4.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (6.8.0)\n","Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.10/dist-packages (from diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (2.1.0+cu118)\n","Collecting accelerate>=0.11.0 (from diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0)\n","  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting coloredlogs (from optimum==1.6.1->optimum-graphcore==0.6.0.dev0)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.6.1->optimum-graphcore==0.6.0.dev0) (1.12)\n","Requirement already satisfied: transformers[sentencepiece]>=4.20.1 in /usr/local/lib/python3.10/dist-packages (from optimum==1.6.1->optimum-graphcore==0.6.0.dev0) (4.35.2)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n","Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2023.6.0)\n","Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.25.1) (2023.7.22)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->optimum-graphcore==0.6.0.dev0) (9.0.0)\n","Collecting pyarrow-hotfix (from datasets->optimum-graphcore==0.6.0.dev0)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets->optimum-graphcore==0.6.0.dev0)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->optimum-graphcore==0.6.0.dev0) (1.5.3)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->optimum-graphcore==0.6.0.dev0) (3.4.1)\n","Collecting multiprocess (from datasets->optimum-graphcore==0.6.0.dev0)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->optimum-graphcore==0.6.0.dev0) (3.8.6)\n","Collecting typing-extensions>=4.1.1 (from librosa)\n","  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.11.0->diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (5.9.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum-graphcore==0.6.0.dev0) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum-graphcore==0.6.0.dev0) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum-graphcore==0.6.0.dev0) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum-graphcore==0.6.0.dev0) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum-graphcore==0.6.0.dev0) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->optimum-graphcore==0.6.0.dev0) (1.3.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4->diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (2.1.0)\n","INFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n","Collecting transformers[sentencepiece]>=4.20.1 (from optimum==1.6.1->optimum-graphcore==0.6.0.dev0)\n","  Downloading transformers-4.35.1-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m99.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.34.0-py3-none-any.whl (7.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.33.3-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: pip is looking at multiple versions of transformers[sentencepiece] to determine which version is compatible with other requirements. This could take a while.\n","  Downloading transformers-4.33.0-py3-none-any.whl (7.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m116.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m112.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m118.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n","  Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m118.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.30.0-py3-none-any.whl (7.2 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m121.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m115.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.29.0-py3-none-any.whl (7.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m114.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m122.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.28.0-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.27.3-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.27.2-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.27.1-py3-none-any.whl (6.7 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.27.0-py3-none-any.whl (6.8 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m88.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m123.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting protobuf<=3.20.2 (from transformers==4.25.1)\n","  Downloading protobuf-3.20.2-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m78.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting humanfriendly>=9.1 (from coloredlogs->optimum==1.6.1->optimum-graphcore==0.6.0.dev0)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (3.17.0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->optimum-graphcore==0.6.0.dev0) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.6.1->optimum-graphcore==0.6.0.dev0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4->diffusers[torch]==0.12.1->optimum-graphcore==0.6.0.dev0) (2.1.3)\n","Building wheels for collected packages: optimum-graphcore\n","  Building wheel for optimum-graphcore (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for optimum-graphcore: filename=optimum_graphcore-0.6.0.dev0-py3-none-any.whl size=212956 sha256=db1dc2cc2dc6b60d8394b66ccd463b00a186ec9bfe3d0b9311d9e405d9ee3f21\n","  Stored in directory: /root/.cache/pip/wheels/13/6a/dd/4991f1d38864742cd4931baeac61d11eb24c77b24b4a9247d1\n","Successfully built optimum-graphcore\n","Installing collected packages: tokenizers, sentencepiece, typing-extensions, pyarrow-hotfix, protobuf, humanfriendly, dill, typeguard, multiprocess, coloredlogs, transformers, diffusers, accelerate, datasets, optimum, optimum-graphcore\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.15.0\n","    Uninstalling tokenizers-0.15.0:\n","      Successfully uninstalled tokenizers-0.15.0\n","  Attempting uninstall: typing-extensions\n","    Found existing installation: typing_extensions 4.5.0\n","    Uninstalling typing_extensions-4.5.0:\n","      Successfully uninstalled typing_extensions-4.5.0\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.2\n","    Uninstalling transformers-4.35.2:\n","      Successfully uninstalled transformers-4.35.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\n","tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed accelerate-0.24.1 coloredlogs-15.0.1 datasets-2.15.0 diffusers-0.12.1 dill-0.3.7 humanfriendly-10.0 multiprocess-0.70.15 optimum-1.6.1 optimum-graphcore-0.6.0.dev0 protobuf-3.20.2 pyarrow-hotfix-0.6 sentencepiece-0.1.99 tokenizers-0.12.1 transformers-4.25.1 typeguard-4.1.5 typing-extensions-4.8.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["google"]}}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools\n","  Cloning https://github.com/graphcore/graphcore-cloud-tools to /tmp/pip-install-z61eo562/graphcore-cloud-tools_a34bba9ca18e4ba6b39f58feda231320\n","  Running command git clone --filter=blob:none --quiet https://github.com/graphcore/graphcore-cloud-tools /tmp/pip-install-z61eo562/graphcore-cloud-tools_a34bba9ca18e4ba6b39f58feda231320\n","  Resolved https://github.com/graphcore/graphcore-cloud-tools to commit f9f8473a94b68ddc1d39efe5a5db094fca046db5\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (6.0.1)\n","Collecting awscli>=1.24.10 (from graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading awscli-1.30.6-py3-none-any.whl (4.3 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting boto3>=1.26 (from graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading boto3-1.29.6-py3-none-any.whl (135 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting ipynbname>=2021.3.2 (from graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading ipynbname-2023.2.0.0-py3-none-any.whl (4.3 kB)\n","Requirement already satisfied: nbformat>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (5.9.2)\n","Collecting botocore==1.32.6 (from awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading botocore-1.32.6-py3-none-any.whl (11.5 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting docutils<0.17,>=0.10 (from awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading docutils-0.16-py2.py3-none-any.whl (548 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m548.2/548.2 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting s3transfer<0.8.0,>=0.7.0 (from awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting colorama<0.4.5,>=0.2.5 (from awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting rsa<4.8,>=3.1.2 (from awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n","Collecting jmespath<2.0.0,>=0.7.1 (from botocore==1.32.6->awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore==1.32.6->awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (2.8.2)\n","Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore==1.32.6->awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (2.0.7)\n","Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (5.5.6)\n","Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (2.19.0)\n","Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (4.19.2)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (5.5.0)\n","Requirement already satisfied: traitlets>=5.1 in /usr/local/lib/python3.10/dist-packages (from nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (5.7.1)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (2023.11.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.31.0)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=2.6->nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.13.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa<4.8,>=3.1.2->awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.5.0)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.2.0)\n","Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (7.34.0)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (6.1.12)\n","Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (6.3.2)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core->nbformat>=5.7.3->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (4.0.0)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (67.7.2)\n","Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools)\n","  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (3.0.41)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (2.16.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.2.0)\n","Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.1.6)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (4.8.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore==1.32.6->awscli>=1.24.10->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (1.16.0)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (23.2.1)\n","Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.8.3)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->ipynbname>=2021.3.2->graphcore-cloud-tools[logger]@ git+https://github.com/graphcore/graphcore-cloud-tools) (0.2.10)\n","Building wheels for collected packages: graphcore-cloud-tools\n","  Building wheel for graphcore-cloud-tools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for graphcore-cloud-tools: filename=graphcore_cloud_tools-0.2.0-py3-none-any.whl size=23880 sha256=c11c5a14e9c47c20875a7419463d29d7f8a9c91ea27b3befe7825cd4b3c7ead5\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-4_o5qdko/wheels/1b/34/f1/50897450d1074acac3db51efcecb8d94ccc0b64eda614da5b4\n","Successfully built graphcore-cloud-tools\n","Installing collected packages: rsa, jmespath, jedi, graphcore-cloud-tools, docutils, colorama, botocore, s3transfer, ipynbname, boto3, awscli\n","  Attempting uninstall: rsa\n","    Found existing installation: rsa 4.9\n","    Uninstalling rsa-4.9:\n","      Successfully uninstalled rsa-4.9\n","  Attempting uninstall: docutils\n","    Found existing installation: docutils 0.18.1\n","    Uninstalling docutils-0.18.1:\n","      Successfully uninstalled docutils-0.18.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\n","llmx 0.0.15a0 requires tiktoken, which is not installed.\n","tensorflow 2.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed awscli-1.30.6 boto3-1.29.6 botocore-1.32.6 colorama-0.4.4 docutils-0.16 graphcore-cloud-tools-0.2.0 ipynbname-2023.2.0.0 jedi-0.19.1 jmespath-1.0.1 rsa-4.7.2 s3transfer-0.7.0\n","Graphcore logger disabled\n"]}],"source":["# Install optimum from source\n","!pip install git+https://github.com/huggingface/optimum-graphcore.git@1f13c9279921bd064a0a857b044d9c18f7fbca13 \"tokenizers<0.13\" \"transformers==4.25.1\" \"soundfile\" \"librosa\" \"matplotlib\"\n","%pip install \"graphcore-cloud-tools[logger] @ git+https://github.com/graphcore/graphcore-cloud-tools\"\n","%load_ext graphcore_cloud_tools.notebook_logging.gc_logger"]},{"cell_type":"code","source":["!pip install poptorch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"slFiGN4VcAxT","executionInfo":{"status":"ok","timestamp":1700898287236,"user_tz":-540,"elapsed":2658,"user":{"displayName":"ë°•ì¤€ì¼","userId":"10460237312093264831"}},"outputId":"45d99f40-5274-4e3b-fac1-a4942fd2fb81"},"id":"slFiGN4VcAxT","execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[31mERROR: Could not find a version that satisfies the requirement poptorch (from versions: none)\u001b[0m\u001b[31m\n","\u001b[0m\u001b[31mERROR: No matching distribution found for poptorch\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"markdown","id":"08888a86","metadata":{"id":"08888a86"},"source":["## Running Whisper on the IPU\n","\n","We start by importing the required modules, some of which are needed to configure the IPU.\n"]},{"cell_type":"code","execution_count":4,"id":"ea6efd44","metadata":{"id":"ea6efd44","executionInfo":{"status":"ok","timestamp":1700898317360,"user_tz":-540,"elapsed":7727,"user":{"displayName":"ë°•ì¤€ì¼","userId":"10460237312093264831"}}},"outputs":[],"source":["# Generic imports\n","import os\n","from datasets import load_dataset\n","import matplotlib.pyplot as plt\n","import librosa\n","import IPython\n","import random\n","\n","\n","# IPU-specific imports\n","from optimum.graphcore import IPUConfig\n","from optimum.graphcore.modeling_utils import to_pipelined\n","from optimum.graphcore.models.whisper import WhisperProcessorTorch\n","\n","# HF-related imports\n","from transformers import WhisperForConditionalGeneration"]},{"cell_type":"markdown","id":"c7a7484f","metadata":{"id":"c7a7484f"},"source":["This notebook demonstrates how to run all sizes of Whisper, assuming you meet the IPU hardware requirements:\n","\n","- `whisper-tiny`, `base` and `small` only requires 2 IPUs (IPU-POD4)\n","- `whisper-medium` requires 4 IPUs (IPU-POD4)\n","- `whisper-large` requires 8 IPUs (IPU-POD16 or a Bow Pod16)"]},{"cell_type":"markdown","id":"734d8d54","metadata":{"id":"734d8d54"},"source":["The Whisper model is available on Hugging Face in several sizes, from `whisper-tiny` with 39M parameters to `whisper-large` with 1550M parameters.\n","\n","The [Whisper architecture](https://openai.com/research/whisper) is an encoder-decoder Transformer, with the audio split into 30-second chunks.\n","- For `whisper-tiny`, `small` and `base`, one IPU is used for the encoder part of the graph and another for the decoder part.\n","- For `whisper-medium `, two IPUs are used to place the encoder part and two others for the decoder part.\n","- For `whisper-large `, four IPUs are used to place the encoder part and four others for the decoder part.\n","\n","The `IPUConfig` object helps to configure the model to be pipelined across the IPUs.\n","The number of transformer layers per IPU can be adjusted by using `layers_per_ipu`."]},{"cell_type":"code","execution_count":6,"id":"1cffea71","metadata":{"id":"1cffea71","executionInfo":{"status":"ok","timestamp":1700898356343,"user_tz":-540,"elapsed":2,"user":{"displayName":"ë°•ì¤€ì¼","userId":"10460237312093264831"}}},"outputs":[],"source":["num_available_ipus=int(os.getenv(\"NUM_AVAILABLE_IPU\", 4))\n","cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"./exe_cache\") + \"/whisper\"\n","\n","default_ipu_config = IPUConfig(executable_cache_dir=cache_dir,\n","                               ipus_per_replica=2)\n","\n","medium_ipu_config = IPUConfig(executable_cache_dir=cache_dir,\n","                             ipus_per_replica=4,\n","                             layers_per_ipu=[12, 12, 13, 11])\n","\n","large_ipu_config = IPUConfig(executable_cache_dir=cache_dir,\n","                             ipus_per_replica=8,\n","                             layers_per_ipu=[8, 8, 8, 8, 6, 9, 9, 8])\n","\n","configs = {\n","    \"tiny\": (\"openai/whisper-tiny.en\",\n","        default_ipu_config),\n","\n","    \"base\": (\"openai/whisper-base.en\",\n","        default_ipu_config),\n","\n","    \"small\": (\"openai/whisper-small.en\",\n","        default_ipu_config),\n","\n","    \"medium\": (\"openai/whisper-medium.en\",\n","        medium_ipu_config),\n","\n","    \"large\": (\"openai/whisper-large-v2\",\n","        large_ipu_config),\n","}\n","\n","\n","def select_whisper_config(size: str, custom_checkpoint: str):\n","    auto_sizes = {4: \"tiny\", 16: \"large\"}\n","    if size == \"auto\":\n","        selected_size = auto_sizes[num_available_ipus]\n","    elif size in configs.keys():\n","        if size == \"large\" and num_available_ipus < 8:\n","            raise ValueError(\"Error: You need at least 8 IPUs to run whisper-large \"\n","                             f\"but your current environment has {num_available_ipus} IPUs available.\")\n","        selected_size = size\n","    else:\n","        raise ValueError(f\"{size} is not a valid size for Whisper\")\n","\n","    model_checkpoint, ipu_config = configs[selected_size]\n","    if custom_checkpoint is not None:\n","        model_checkpoint = custom_checkpoint\n","\n","    print(f\"Using whisper-{selected_size} config with the checkpoint '{model_checkpoint}'.\")\n","    return model_checkpoint, ipu_config"]},{"cell_type":"markdown","id":"f0d22c55","metadata":{"id":"f0d22c55"},"source":["Select the Whisper size bellow, try `\"tiny\"`,`\"base\"`, `\"small\"`, `\"medium\"`, `\"large\"`  or let the `\"auto\"` mode choose for you."]},{"cell_type":"code","execution_count":10,"id":"f919498b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"id":"f919498b","executionInfo":{"status":"error","timestamp":1700898384572,"user_tz":-540,"elapsed":283,"user":{"displayName":"ë°•ì¤€ì¼","userId":"10460237312093264831"}},"outputId":"09c9c980-508d-4aae-dc0d-4b38c1940b03"},"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-2e7b4793edca>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_whisper_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-6-ba6f5e24fd5d>\u001b[0m in \u001b[0;36mselect_whisper_config\u001b[0;34m(size, custom_checkpoint)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{size} is not a valid size for Whisper\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mipu_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_checkpoint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"]}],"source":["model_checkpoint, ipu_config = select_whisper_config(\"auto\", custom_checkpoint=None)"]},{"cell_type":"markdown","id":"eff8bcf6","metadata":{"id":"eff8bcf6"},"source":["You can also use a custom checkpoint from Hugging Face Hub using the argument `custom_checkpoint` above. In this case, you have to make sure that `size` matches the checkpoint model size."]},{"cell_type":"code","execution_count":null,"id":"8c5d72f3-cbd6-462f-9741-1726d412c4eb","metadata":{"id":"8c5d72f3-cbd6-462f-9741-1726d412c4eb"},"outputs":[],"source":["# Instantiate processor and model\n","processor = WhisperProcessorTorch.from_pretrained(model_checkpoint)\n","model = WhisperForConditionalGeneration.from_pretrained(model_checkpoint)\n","\n","# Adapt whisper-tiny to run on the IPU\n","\n","pipelined_model = to_pipelined(model, ipu_config)\n","pipelined_model = pipelined_model.parallelize(\n","    for_generation=True,\n","    use_cache=True,\n","    batch_size=1,\n","    max_length=448,\n","    on_device_generation_steps=16,\n","    use_encoder_output_buffer=True).half()"]},{"cell_type":"markdown","id":"9e99620b","metadata":{"id":"9e99620b"},"source":["Now we can load the dataset and process an example audio file.\n","If precompiled models are not available, then the first run of the model triggers two graph compilations.\n","This means that our first test transcription could take a minute or two to run, but subsequent runs will be much faster."]},{"cell_type":"code","execution_count":null,"id":"8ab692b6","metadata":{"id":"8ab692b6"},"outputs":[],"source":["# load the dataset and read an example sound file\n","ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n","test_sample = ds[2]\n","sample_rate = test_sample['audio']['sampling_rate']\n","\n","def transcribe(data, rate):\n","    input_features = processor(data, return_tensors=\"pt\", sampling_rate=rate).input_features.half()\n","\n","    # This triggers a compilation, unless a precompiled model is available.\n","    sample_output = pipelined_model.generate(\n","        input_features,\n","        use_cache=True,\n","        do_sample=False,\n","        max_length=448,\n","        min_length=3)\n","    transcription = processor.batch_decode(sample_output, skip_special_tokens=True)[0]\n","    return transcription\n","\n","test_transcription = transcribe(test_sample[\"audio\"][\"array\"], sample_rate)"]},{"cell_type":"markdown","id":"aa59411d","metadata":{"id":"aa59411d"},"source":["In the next cell, we compare the expected text from the dataset with the transcribed result from the model.\n","There will typically be some small differences, but even `whisper-tiny` does a great job! It even adds punctuation.\n","\n","You can listen to the audio and compare the model result yourself using the controls below."]},{"cell_type":"code","execution_count":null,"id":"17947b7c","metadata":{"id":"17947b7c"},"outputs":[],"source":["print(f\"Expected: {test_sample['text']}\\n\")\n","print(f\"Transcribed: {test_transcription}\")\n","\n","plt.figure(figsize=(14, 5))\n","librosa.display.waveshow(test_sample[\"audio\"][\"array\"], sr=sample_rate)\n","IPython.display.Audio(test_sample[\"audio\"][\"array\"], rate=sample_rate)"]},{"cell_type":"markdown","id":"217f7821-1ddb-425e-995e-a9f084c7ff0b","metadata":{"id":"217f7821-1ddb-425e-995e-a9f084c7ff0b"},"source":["The model only needs to be compiled once. Subsequent inferences will be much faster.\n","In the cell below, we repeat the exercise but with a random example from the dataset.\n","\n","You might like to re-run this next cell multiple times to get different comparisons."]},{"cell_type":"code","execution_count":null,"id":"8c8e9ca3-a932-4e66-97c7-8ffe98d00bf1","metadata":{"id":"8c8e9ca3-a932-4e66-97c7-8ffe98d00bf1"},"outputs":[],"source":["idx = random.randint(0, ds.num_rows - 1)\n","data = ds[idx][\"audio\"][\"array\"]\n","\n","print(f\"Example #{idx}\\n\")\n","print(f\"Expected: {ds[idx]['text']}\\n\")\n","print(f\"Transcribed: {transcribe(data, sample_rate)}\")\n","\n","plt.figure(figsize=(14, 5))\n","librosa.display.waveshow(data, sr=sample_rate)\n","IPython.display.Audio(data, rate=sample_rate, autoplay=True)"]},{"cell_type":"markdown","id":"3625a6bf","metadata":{"id":"3625a6bf"},"source":["Finally, we detach the process from the IPUs when we are done to make the IPUs available to other users."]},{"cell_type":"code","execution_count":null,"id":"24c1175a","metadata":{"id":"24c1175a"},"outputs":[],"source":["pipelined_model.detachFromDevice()"]},{"cell_type":"markdown","id":"08b4e580-703e-4329-9dba-808a3a1096c8","metadata":{"id":"08b4e580-703e-4329-9dba-808a3a1096c8"},"source":["## Next Steps\n","\n","The `whisper-tiny` model used here is very fast for inference and so cheap to run, but its accuracy can be improved.\n","The `whisper-base`, `whisper-small` and `whisper-medium` models have 74M, 244M and 769 M parameters respectively (compared to just 39M for `whisper-tiny`). You can try out `whisper-base`, `whisper-small` and `whisper-medium` by changing `select_whisper_config(\"auto\")` (at the beginning of this notebook) to:\n","- `select_whisper_config(\"base\")`\n","- `select_whisper_config(\"small\")`\n","- `select_whisper_config(\"medium\")` respectively.\n","\n","Larger models and multilingual models are also available.\n","To access the multilingual models, remove the `.en` from the checkpoint name. Note however that the multilingual models are slightly less accurate for this English transcription task but they can be used for transcribing other languages or for translating to English.\n","\n","The largest model `whisper-large` has 1550M parameters and requires a 8-IPUs pipeline.\n","You can try it by setting `select_whisper_config(\"large\")`\n","To run it you will need more than the IPU-POD4. On Paperspace, this is available using either an IPU-POD16 or a Bow Pod16 machine. Please contact Graphcore if you need assistance running these larger models.\n"]},{"cell_type":"markdown","id":"21ff7629","metadata":{"id":"21ff7629"},"source":["## Conclusion\n","\n","In this notebook, we demonstrated using Whisper for speech recognition and transcription on the IPU.\n","We used the Optimum Graphcore package to interface between the IPU and the Hugging Face Transformers library. This meant that only a few lines of code were needed to get this state-of-the-art automated speech recognition model running on IPUs."]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}